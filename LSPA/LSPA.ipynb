{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSPA - illustrative examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pystoned'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-cd9b55f363c2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mlspa_main\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLSPAEstimator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpystoned\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCNLS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpystoned\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplot2d\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpystoned\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCET_ADDI\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFUN_COST\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRTS_VRS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mOPT_LOCAL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFUN_PROD\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRTS_CRS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pystoned'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from collections import OrderedDict\n",
    "\n",
    "from regression import max_affine_predict, max_affine_fit_partition\n",
    "from lspa_main import LSPAEstimator\n",
    "\n",
    "from pystoned import CNLS\n",
    "from pystoned.plot import plot2d\n",
    "from pystoned.constant import CET_ADDI, FUN_COST, RTS_VRS, OPT_LOCAL, FUN_PROD, RTS_CRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random initialization \n",
    "def set_random_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(random.randint(0, 1e8))\n",
    "\n",
    "seed_limit = 1e6\n",
    "global_random_seed = 100 + int(np.round((time.time() % 1) * seed_limit))\n",
    "set_random_seed(global_random_seed)\n",
    "setup_random_seed = np.random.randint(seed_limit)\n",
    "data_random_seed = np.random.randint(seed_limit)\n",
    "training_random_seed = np.random.randint(seed_limit)\n",
    "testing_random_seed = np.random.randint(seed_limit)\n",
    "\n",
    "# parameters initialization \n",
    "nruns = 10  # number of experiment runs\n",
    "ntestsamples = int(1e6)  # number of test samples to generate\n",
    "\n",
    "parallel_nworkers = 1 \n",
    "parallel_backend = 'multiprocessing'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_random_seed(19)\n",
    "x = np.sort(np.random.uniform(low=-10, high=10, size=100))\n",
    "x = x.reshape(len(x),1)\n",
    "u = np.random.normal(loc=0, scale=0.5, size=100).reshape(100,1)\n",
    "u = u.reshape(len(u),1)\n",
    "y_true = (x**2 - 2*x + 10)/10\n",
    "y = y_true - u\n",
    "y = y.reshape(len(y))\n",
    "y_true = y_true.reshape(len(y_true))\n",
    "x_test = np.sort(np.random.uniform(low=-10, high=10, size=200))\n",
    "x_test = x_test.reshape(len(x_test), 1)\n",
    "y_test = (x_test**2 - 2*x_test + 10)/10\n",
    "y_test = y_test.reshape(len(y_test))\n",
    "\n",
    "# fit OLS model\n",
    "ols_model = np.linalg.lstsq(x, y, rcond=-1)[0]\n",
    "ols_yhat_train = np.sum(x * ols_model, axis=1)\n",
    "ols_train_errors = np.round(np.sum(np.square(ols_yhat_train - y)) / len(y), decimals=4)\n",
    "ols_train_risk = np.round(np.sum(np.square(ols_yhat_train - y_true)) / len(y), decimals=4)\n",
    "ols_yhat_test = np.sum(x_test * ols_model, axis=1)\n",
    "ols_test_errors = np.round(np.sum(np.square(ols_yhat_test - y_test)) / len(y_test), decimals=4)\n",
    "\n",
    "# fit LSPA model\n",
    "def lspa_model(n,d, num):\n",
    "    ncenters = n**(d/(d+4))\n",
    "    nrestarts = d\n",
    "    nfinalsteps = n\n",
    "    return LSPAEstimator(train_args={'ncenters': num, 'nrestarts': nrestarts, 'nfinalsteps': nfinalsteps})\n",
    "\n",
    "lspa = lspa_model(x.shape[0],x.shape[1], 4)\n",
    "model_lspa = lspa.train(x, y)\n",
    "lspa_yhat_train = lspa.predict(model_lspa, x)\n",
    "lspa_train_risk = np.round(np.sum(np.square(lspa_yhat_train - y_true)) / len(y_true), decimals=4)\n",
    "lspa_train_error = np.round(np.sum(np.square(lspa_yhat_train - y)) / len(y), decimals=4)\n",
    "lspa_yhat_test = lspa.predict(model_lspa, x_test)\n",
    "lspa_test_error = np.round(np.sum(np.square(lspa_yhat_test - y_test)) / len(y_test), decimals=4)\n",
    "\n",
    "# fit CNLS model\n",
    "model = CNLS.CNLS(y, x, z=None, cet = CET_ADDI, fun = FUN_COST, rts = RTS_VRS)\n",
    "model.optimize()\n",
    "cnls_yhat_train = model.get_frontier()\n",
    "cnls_train_error = np.round(np.sum(np.square(cnls_yhat_train - y)) / len(y), decimals=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(11)\n",
    "plt.scatter(x, y, marker='x',s=50, c='k',label='data points')\n",
    "plt.plot(x, y_true, markersize=50, c='b',label='true function')\n",
    "plt.plot(x, lspa_yhat_train, markersize=50, c='r', label='LSPA')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlabel('x', fontsize=20)\n",
    "plt.ylabel('y=0.1(x^2-2x+10)', fontsize=20)\n",
    "plt.title('train result(num_centers=6)', fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(12)\n",
    "plt.scatter(x_test, y_test, marker='x',s=50, c='k',label='data points')\n",
    "plt.plot(x_test, y_test, markersize=50, c='b',label='true function')\n",
    "plt.plot(x_test, lspa_yhat_test, markersize=50, c='r', label='LSPA')\n",
    "plt.plot(x_test, ols_yhat_test, markersize=50, c='g', label='OLS')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlabel('x', fontsize=20)\n",
    "plt.ylabel('y=0.1(x^2-2x+10)',fontsize=15)\n",
    "plt.title('test result', fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_random_seed(19)\n",
    "x = np.sort(np.random.uniform(low=1, high=10, size=50))\n",
    "x = x.reshape(len(x),1)\n",
    "u = np.random.normal(loc=0, scale=0.5, size=50).reshape(50,1)\n",
    "u = u.reshape(len(u),1)\n",
    "y_true = (x**2 - 2*x + 10)/10\n",
    "y = y_true - u\n",
    "y = y.reshape(len(y))\n",
    "y_true = y_true.reshape(len(y_true))\n",
    "x_test = np.sort(np.random.uniform(low=1, high=10, size=100))\n",
    "x_test = x_test.reshape(len(x_test), 1)\n",
    "y_test = (x_test**2 - 2*x_test + 10)/10\n",
    "y_test = y_test.reshape(len(y_test))\n",
    "\n",
    "# fit OLS model\n",
    "ols_model = np.linalg.lstsq(x, y, rcond=-1)[0]\n",
    "ols_yhat_train = np.sum(x * ols_model, axis=1)\n",
    "ols_train_errors = np.round(np.sum(np.square(ols_yhat_train - y)) / len(y), decimals=4)\n",
    "ols_train_risk = np.round(np.sum(np.square(ols_yhat_train - y_true)) / len(y), decimals=4)\n",
    "ols_yhat_test = np.sum(x_test * ols_model, axis=1)\n",
    "ols_test_errors = np.round(np.sum(np.square(ols_yhat_test - y_test)) / len(y_test), decimals=4)\n",
    "\n",
    "# fit LSPA model\n",
    "def lspa_model(n,d, num):\n",
    "    ncenters = n**(d/(d+4))\n",
    "    nrestarts = d\n",
    "    nfinalsteps = n\n",
    "    return LSPAEstimator(train_args={'ncenters': num, 'nrestarts': nrestarts, 'nfinalsteps': nfinalsteps})\n",
    "\n",
    "lspa = lspa_model(x.shape[0],x.shape[1], 3)\n",
    "model_lspa = lspa.train(x, y)\n",
    "lspa_yhat_train = lspa.predict(model_lspa, x)\n",
    "lspa_train_risk = np.round(np.sum(np.square(lspa_yhat_train - y_true)) / len(y_true), decimals=4)\n",
    "lspa_train_error = np.round(np.sum(np.square(lspa_yhat_train - y)) / len(y), decimals=4)\n",
    "lspa_yhat_test = lspa.predict(model_lspa, x_test)\n",
    "lspa_test_error = np.round(np.sum(np.square(lspa_yhat_test - y_test)) / len(y_test), decimals=4)\n",
    "\n",
    "# fit CNLS model\n",
    "model = CNLS.CNLS(y, x, z=None, cet = CET_ADDI, fun = FUN_COST, rts = RTS_VRS)\n",
    "model.optimize()\n",
    "cnls_yhat_train = model.get_frontier()\n",
    "cnls_train_error = np.round(np.sum(np.square(cnls_yhat_train - y)) / len(y), decimals=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(10)\n",
    "plt.scatter(x, y, marker='x',s=50, c='k',label='data points')\n",
    "plt.plot(x, y_true, markersize=50, c='b',label='true function')\n",
    "plt.plot(x, ols_yhat_train, markersize=50, c='g', label='OLS')\n",
    "plt.plot(x, lspa_yhat_train, markersize=50, c='r', label='LSPA')\n",
    "plt.plot(x, cnls_yhat_train, markersize=50, c='y', label='CNLS')\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3 - Effect of number of centers on LSPA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paritition_effect_lspa(x, y, y_true):\n",
    "    num_centers = np.arange(2, len(x))\n",
    "    train_error = []\n",
    "    test_error = []\n",
    "    for i in num_centers:\n",
    "        lspa = LSPAEstimator(train_args={'ncenters': i, 'nrestarts': 5, 'nfinalsteps': x.shape[0]})\n",
    "        model = lspa.train(x, y)\n",
    "        lspa_yhat_train = lspa.predict(model, x)\n",
    "        lspa_train_error = np.round(np.sum(np.square(lspa_yhat_train - y)) / len(y), decimals=4)\n",
    "        train_error.append(lspa_train_error)\n",
    "        lspa_yhat_test = lspa.predict(model, x_test)\n",
    "        lspa_test_error = np.round(np.sum(np.square(lspa_yhat_test - y_test)) / len(y_test), decimals=4)\n",
    "        test_error.append(lspa_test_error)\n",
    "    \n",
    "    train_error = np.array(train_error)\n",
    "\n",
    "    error_change_percent = list(np.diff(train_error)/train_error[0:-1])\n",
    "    error_change_percent.insert(0,0)\n",
    "    error_change_percent = np.array(error_change_percent)\n",
    "    \n",
    "    figure_seed = int(np.abs(np.random.randn(1)*100))\n",
    "    plt.figure(figure_seed)\n",
    "    plt.plot(num_centers, error_change_percent, label='error change')\n",
    "    plt.plot(num_centers, train_error,label='train error')\n",
    "    plt.xlabel('number of centers', fontsize=15)\n",
    "    plt.ylabel('error change/ train error', fontsize=15)\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    return train_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trian_error = paritition_effect_lspa(x, y, y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 4 - LSPA on high-dimensional data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_data_generate(dim, n_train, n_test):\n",
    "    set_random_seed(data_random_seed + dim*10)\n",
    "    \n",
    "    x = np.random.randn(n_train, dim)\n",
    "    y_true = 0.5 * np.sum(np.square(x), axis=1)\n",
    "    sample_noise = np.random.randn(n_train) * 0.3\n",
    "    y = y_true + sample_noise\n",
    "    \n",
    "    x_test = np.random.randn(int(n_test), dim)\n",
    "    y_test = 0.5 * np.sum(np.square(x_test), axis=1)\n",
    "    \n",
    "    return x, y, y_true, x_test, y_test\n",
    "\n",
    "x, y, y_true, x_test, y_test = function_data_generate(3, 100, 1e6)\n",
    "x_norms = np.linalg.norm(x, axis=1)\n",
    "x_test_norms = np.linalg.norm(x_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_weight = []\n",
    "train_error = []\n",
    "test_error = []\n",
    "for i in range(5):\n",
    "    set_random_seed(training_random_seed + i*100)\n",
    "    lspa = lspa_model(x.shape[0],x.shape[1])\n",
    "    model = lspa.train(x, y)\n",
    "    yhat = lspa.predict(model, x)\n",
    "    lspa_train_error = np.mean(np.square(yhat - y))\n",
    "    yhat_test = lspa.predict(model, x_test)\n",
    "    lspa_test_error = np.mean(np.square(yhat_test - y_test))\n",
    "    \n",
    "    result_weight.append(model.weights.shape[0])\n",
    "    train_error.append(lspa_train_error)\n",
    "    test_error.append(lspa_test_error)\n",
    "\n",
    "index_min_train_error = np.argmin(np.array(train_error))\n",
    "lspa_weight = result_weight[index_min_train_error]\n",
    "lspa_train_best_error = train_error[index_min_train_error]\n",
    "lspa_test_best_error = test_error[index_min_train_error]\n",
    "\n",
    "ols_model = np.linalg.lstsq(x, y, rcond=-1)[0]\n",
    "ols_yhat_train = np.sum(x * ols_model, axis=1)\n",
    "ols_train_errors = np.round(np.sum(np.square(ols_yhat_train - y)) / len(y), decimals=4)\n",
    "ols_yhat_test = np.sum(x_test * ols_model, axis=1)\n",
    "ols_test_errors = np.round(np.sum(np.square(ols_yhat_test - y_test)) / len(y_test), decimals=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
